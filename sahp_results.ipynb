{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:00:27.694606Z",
     "start_time": "2021-10-14T04:00:27.676653Z"
    }
   },
   "outputs": [],
   "source": [
    "from train_functions import train_sahp\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from utils.load_synth_data import process_loaded_sequences\n",
    "from utils.util import get_batch,count_parameters\n",
    "from utils.atten_optimizer import NoamOpt\n",
    "from train_functions.train_sahp import make_model,eval_sahp,prediction_evaluation,MaskBatch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "\n",
    "def get_pairwise_times(event_time):\n",
    "    xt_bar = event_time.unsqueeze(1). \\\n",
    "        expand(event_time.size(0), event_time.size(1), event_time.size(1))\n",
    "    xt = xt_bar.transpose(1, 2)\n",
    "    return (xt_bar, xt)\n",
    "\n",
    "\n",
    "def get_pairwise_type_embeddings(embeddings):\n",
    "    xd_bar = embeddings.unsqueeze(1).expand(embeddings.size(\n",
    "        0), embeddings.size(1), embeddings.size(1), embeddings.size(-1))\n",
    "    xd = xd_bar.transpose(1, 2)\n",
    "\n",
    "    return (xd_bar, xd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synth Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:03:28.189301Z",
     "start_time": "2021-10-14T04:03:28.002743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sequence_length: 323\n"
     ]
    }
   ],
   "source": [
    "model = train_sahp.make_model(max_sequence_length=324)\n",
    "model_dict =torch.load('saved_models/sahp-synthetic_hidden16-20210622-205430',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "with open('data/simulated/hawkes_synthetic_random_2d_20191130-180837.pkl', 'rb') as f:\n",
    "    loaded_hawkes_data = pickle.load(f)\n",
    "\n",
    "\n",
    "seq_times, seq_types, seq_lengths, _ = process_loaded_sequences(loaded_hawkes_data, 2)\n",
    "\n",
    "total_sample_size = seq_times.size(0)\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * total_sample_size)\n",
    "dev_ratio =0.1\n",
    "dev_size = int(dev_ratio * total_sample_size)\n",
    "## Split Traning and Test Sets\n",
    "train_seq_times = seq_times[:train_size]\n",
    "train_seq_types = seq_types[:train_size]\n",
    "train_seq_lengths = seq_lengths[:train_size]\n",
    "\n",
    "\n",
    "dev_seq_times = seq_times[train_size:train_size + dev_size]  # train_size+dev_size\n",
    "dev_seq_types = seq_types[train_size:train_size + dev_size]\n",
    "dev_seq_lengths = seq_lengths[train_size:train_size + dev_size]\n",
    "\n",
    "test_seq_times = seq_times[-dev_size:]\n",
    "test_seq_types = seq_types[-dev_size:]\n",
    "test_seq_lengths = seq_lengths[-dev_size:]\n",
    "\n",
    "\n",
    "## sequence length\n",
    "train_seq_lengths, reorder_indices_train = train_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "train_seq_times = train_seq_times[reorder_indices_train]\n",
    "train_seq_types = train_seq_types[reorder_indices_train]\n",
    "#\n",
    "dev_seq_lengths, reorder_indices_dev = dev_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "dev_seq_times = dev_seq_times[reorder_indices_dev]\n",
    "dev_seq_types = dev_seq_types[reorder_indices_dev]\n",
    "\n",
    "test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "test_seq_times = test_seq_times[reorder_indices_test]\n",
    "test_seq_types = test_seq_types[reorder_indices_test]\n",
    "\n",
    "max_sequence_length = max(train_seq_lengths[0], dev_seq_lengths[0], test_seq_lengths[0])\n",
    "print('max_sequence_length: {}'.format(max_sequence_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T03:59:48.065939Z",
     "start_time": "2021-10-14T03:59:48.049017Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_attention_scores_for_sahp(data,model):\n",
    "    tmax = loaded_hawkes_data['tmax']\n",
    "\n",
    "    seq_times, seq_types, seq_lengths, _ = process_loaded_sequences(loaded_hawkes_data, 2)\n",
    "\n",
    "    total_sample_size = seq_times.size(0)\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(train_ratio * total_sample_size)\n",
    "    dev_ratio =0.1\n",
    "    dev_size = int(dev_ratio * total_sample_size)\n",
    "    ## Split Traning and Test Sets\n",
    "    train_seq_times = seq_times[:train_size]\n",
    "    train_seq_types = seq_types[:train_size]\n",
    "    train_seq_lengths = seq_lengths[:train_size]\n",
    "\n",
    "\n",
    "    dev_seq_times = seq_times[train_size:train_size + dev_size]  # train_size+dev_size\n",
    "    dev_seq_types = seq_types[train_size:train_size + dev_size]\n",
    "    dev_seq_lengths = seq_lengths[train_size:train_size + dev_size]\n",
    "\n",
    "    test_seq_times = seq_times[-dev_size:]\n",
    "    test_seq_types = seq_types[-dev_size:]\n",
    "    test_seq_lengths = seq_lengths[-dev_size:]\n",
    "\n",
    "\n",
    "    ## sequence length\n",
    "    train_seq_lengths, reorder_indices_train = train_seq_lengths.sort(descending=True)\n",
    "    # # Reorder by descending sequence length\n",
    "    train_seq_times = train_seq_times[reorder_indices_train]\n",
    "    train_seq_types = train_seq_types[reorder_indices_train]\n",
    "    #\n",
    "    dev_seq_lengths, reorder_indices_dev = dev_seq_lengths.sort(descending=True)\n",
    "    # # Reorder by descending sequence length\n",
    "    dev_seq_times = dev_seq_times[reorder_indices_dev]\n",
    "    dev_seq_types = dev_seq_types[reorder_indices_dev]\n",
    "\n",
    "    test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "    # # Reorder by descending sequence length\n",
    "    test_seq_times = test_seq_times[reorder_indices_test]\n",
    "    test_seq_types = test_seq_types[reorder_indices_test]\n",
    "\n",
    "    max_sequence_length = max(train_seq_lengths[0], dev_seq_lengths[0], test_seq_lengths[0])\n",
    "    print('max_sequence_length: {}'.format(max_sequence_length))\n",
    "    \n",
    "    \n",
    "    batch_size = 1\n",
    "    device = 'cpu'\n",
    "\n",
    "    kernels = [[],[],[],[]]\n",
    "    all_times = [[],[],[],[]]\n",
    "    for i_batch in range(400):\n",
    "        batch_onehot, batch_seq_times, batch_dt, batch_seq_types, _, _, _, batch_seq_lengths = \\\n",
    "        get_batch(batch_size, i_batch, model, test_seq_lengths, test_seq_times, test_seq_types,\n",
    "                       rnn=False)\n",
    "\n",
    "        batch_seq_types = batch_seq_types[:, 1:]\n",
    "\n",
    "        masked_seq_types = MaskBatch(batch_seq_types, pad=model.process_dim,\n",
    "                                     device=device)  # exclude the first added even\n",
    "\n",
    "        model.forward(batch_dt, masked_seq_types.src, masked_seq_types.src_mask)\n",
    "\n",
    "\n",
    "\n",
    "        type_embedding = model.type_emb(batch_seq_types) * math.sqrt(model.d_model)  #\n",
    "        position_embedding = model.position_emb(batch_seq_types, batch_dt)\n",
    "        x = type_embedding + position_embedding\n",
    "\n",
    "        (xt_bar, xt) = get_pairwise_times(batch_seq_times[:,1:])\n",
    "        d = torch.abs(xt_bar - xt)\n",
    "        xd_bar, xd = get_pairwise_times(batch_seq_types)\n",
    "        scores = model.attention.scores[:,1,:,:]\n",
    "    # scores =scores[0].unsqueeze(0)\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                mask = (xd_bar==i)*(xd ==j)\n",
    "                times = d[mask]\n",
    "                kernel = scores[mask]\n",
    "                if i ==0 and j == 0:\n",
    "                    index =0\n",
    "                elif i ==0 and j ==1:\n",
    "                    index =1\n",
    "                elif i ==1 and j ==0:\n",
    "                    index = 2\n",
    "                else:\n",
    "                    index = 3\n",
    "                all_times[index].append(times.detach().numpy())\n",
    "                kernels[index].append(kernel.detach().numpy())\n",
    "                \n",
    "    times = np.concatenate(all_times[1])\n",
    "    k_val = np.concatenate(kernels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:04:03.684389Z",
     "start_time": "2021-10-14T04:03:54.987064Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "device = 'cpu'\n",
    "\n",
    "kernels = [[],[],[],[]]\n",
    "all_times = [[],[],[],[]]\n",
    "for i_batch in range(400):\n",
    "    batch_onehot, batch_seq_times, batch_dt, batch_seq_types, _, _, _, batch_seq_lengths = \\\n",
    "    get_batch(batch_size, i_batch, model, test_seq_lengths, test_seq_times, test_seq_types,\n",
    "                   rnn=False)\n",
    "\n",
    "    batch_seq_types = batch_seq_types[:, 1:]\n",
    "\n",
    "    masked_seq_types = MaskBatch(batch_seq_types, pad=model.process_dim,\n",
    "                                 device=device)  # exclude the first added even\n",
    "    \n",
    "    model.forward(batch_dt, masked_seq_types.src, masked_seq_types.src_mask)\n",
    "    \n",
    "    \n",
    "\n",
    "    type_embedding = model.type_emb(batch_seq_types) * math.sqrt(model.d_model)  #\n",
    "    position_embedding = model.position_emb(batch_seq_types, batch_dt)\n",
    "    x = type_embedding + position_embedding\n",
    "\n",
    "    (xt_bar, xt) = get_pairwise_times(batch_seq_times[:,1:])\n",
    "    d = torch.abs(xt_bar - xt)\n",
    "    xd_bar, xd = get_pairwise_times(batch_seq_types)\n",
    "    scores = model.attention.scores[:,1,:,:]\n",
    "# scores =scores[0].unsqueeze(0)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            mask = (xd_bar==i)*(xd ==j)\n",
    "            times = d[mask]\n",
    "            kernel = scores[mask]\n",
    "            if i ==0 and j == 0:\n",
    "                index =0\n",
    "            elif i ==0 and j ==1:\n",
    "                index =1\n",
    "            elif i ==1 and j ==0:\n",
    "                index = 2\n",
    "            else:\n",
    "                index = 3\n",
    "            all_times[index].append(times.detach().numpy())\n",
    "            kernels[index].append(kernel.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:56:41.688890Z",
     "start_time": "2021-10-14T02:56:34.922311Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 400/400 [00:06<00:00, 59.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 2.2363861209728695\n",
      "Type prediction score: 0.5575\n",
      "tensor(0.0201)\n"
     ]
    }
   ],
   "source": [
    "## Get Result Metrics\n",
    "avg_rmse, types_predict_score, results = prediction_evaluation(\n",
    "    device, model, test_seq_lengths, test_seq_times, test_seq_types, 1, tmax)\n",
    "\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:33:57.702364Z",
     "start_time": "2021-10-14T02:33:57.680421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07079299"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_val[times == 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:17:52.173725Z",
     "start_time": "2021-10-14T04:17:52.163753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10150479, dtype=torch.int32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_seq_lengths**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:04:14.926141Z",
     "start_time": "2021-10-14T04:04:14.880855Z"
    }
   },
   "outputs": [],
   "source": [
    "times = [np.concatenate(cur) for cur in all_times]\n",
    "k_val = [np.concatenate(cur) for cur in kernels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:04:16.668157Z",
     "start_time": "2021-10-14T04:04:16.280842Z"
    }
   },
   "outputs": [],
   "source": [
    "# times = np.concatenate(all_times[0])\n",
    "# k_val = np.concatenate(kernels[1])    \n",
    "triggering_kernels = {'times':times,'scores':k_val}\n",
    "np.save('sahp_kernels.npy',triggering_kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:26:05.482007Z",
     "start_time": "2021-10-14T02:26:04.392692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtFklEQVR4nO3deXxW1b3v8c8vMxkhIyEMCRAQkFEEVOoEKtoqttqK9qjtpcf2Hj3aHnt69NzT3l5ve672tFpbtadWaa1Hi9ZqpUdaJ5wHJCCKTBJmIkMIIQOQkJDf/ePZwccM5AGSPAl8369XXtl77bXXs/Z+Pdm/rLXXXtvcHRERkXAx0a6AiIj0PAoOIiLSioKDiIi0ouAgIiKtKDiIiEgrcdGuQGfIzs72wsLCaFdDRKRXWbp06W53z2lr2wkRHAoLCykpKYl2NUREehUz29zeNnUriYhIKwoOIiLSioKDiIi0ouAgIiKtKDiIiEgrCg4iItKKgoOIiLSi4CAiIq0oOIiISCsnxBPS3eXxxVvaTL9m6uBuromISNdSy0FERFpRcBARkVYUHEREpBUFBxERaUXBQUREWlFwEBGRVhQcRESklYiCg5nNMrO1ZlZqZre1sT3RzJ4Iti82s8IgPcvMXjGzWjO7Lyx/mpktD/vZbWY/D7Z9zczKw7Z9o3MOVUREItXhQ3BmFgvcD1wAbAOWmNkCd18Vlm0uUOnuw81sDnAXcBVQB3wfODX4AcDda4AJYZ+xFHg6rLwn3P2mYz0oERE5PpG0HKYApe6+wd0PAvOB2S3yzAYeCZafAmaYmbn7Pnd/k1CQaJOZjQBygTeOuvYiItIlIgkOBcDWsPVtQVqbedy9EagCsiKswxxCLQUPS7vCzD40s6fMbFBbO5nZDWZWYmYl5eXlEX6UiIhEoifckJ4D/CFs/S9AobuPA17k0xbJZ7j7g+4+2d0n5+TkdEM1RUROHpEEhzIg/L/3gUFam3nMLA7IACo6KtjMxgNx7r60Oc3dK9y9Plh9CDgtgjqKiEgniiQ4LAGKzazIzBII/ae/oEWeBcD1wfKVwKIW3UTtuZrPthows/yw1cuA1RGUIyIinajD0Uru3mhmNwHPA7HAPHdfaWZ3ACXuvgB4GHjUzEqBPYQCCABmtglIBxLM7HLgwrCRTl8BLmnxkTeb2WVAY1DW14798ERE5FhE9D4Hd18ILGyR9oOw5Trgy+3sW3iEcoe2kXY7cHsk9RIRka7RE25Ii4hID6PgICIirSg4iIhIKwoOIiLSioKDiIi0ouAgIiKtKDiIiEgrCg4iItKKgoOIiLSi4CAiIq0oOIiISCsKDiIi0oqCg4iItKLgICIirSg4iIhIKwoOIiLSioKDiIi0ouAgIiKtKDiIiEgrEQUHM5tlZmvNrNTMbmtje6KZPRFsX2xmhUF6lpm9Yma1ZnZfi31eDcpcHvzkHqksERHpPh0GBzOLBe4HLgZGA1eb2egW2eYCle4+HLgHuCtIrwO+D3y3neK/6u4Tgp9dHZQlIiLdJJKWwxSg1N03uPtBYD4wu0We2cAjwfJTwAwzM3ff5+5vEgoSkWqzrKPYX0REjlMkwaEA2Bq2vi1IazOPuzcCVUBWBGX/NuhS+n5YAIioLDO7wcxKzKykvLw8go8SEZFIRfOG9FfdfSzwueDn2qPZ2d0fdPfJ7j45JyenSyooInKyiiQ4lAGDwtYHBmlt5jGzOCADqDhSoe5eFvyuAR4n1H11TGWJiEjniiQ4LAGKzazIzBKAOcCCFnkWANcHy1cCi9zd2yvQzOLMLDtYjge+AHx0LGWJiEjni+sog7s3mtlNwPNALDDP3Vea2R1AibsvAB4GHjWzUmAPoQACgJltAtKBBDO7HLgQ2Aw8HwSGWOAl4DfBLu2WJSIi3aPD4ADg7guBhS3SfhC2XAd8uZ19C9sp9rR28rdbloiIdA89IS0iIq0oOIiISCsKDiIi0oqCg4iItKLgICIirSg4iIhIKwoOIiLSioKDiIi0ouAgIiKtKDiIiEgrCg4iItKKgoOIiLSi4CAiIq0oOIiISCsKDiIi0oqCw3GqazjEvvrGaFdDRKRTRfSyH/msJncWrtjOup21lNfW88z7ZfzlH6dHu1oiIp1GLYdjsHd/A2+vryApPoZT+qexoqyKjbv3RbtaIiKdRsHhGOw9cBCAC0b359LxAwB4fuWOaFZJRKRTRRQczGyWma01s1Izu62N7Ylm9kSwfbGZFQbpWWb2ipnVmtl9YfmTzew5M1tjZivN7M6wbV8zs3IzWx78fKMTjrNTVe1vAKBvn3j6JScwZkA6Lyg4iMgJpMPgYGaxwP3AxcBo4GozG90i21yg0t2HA/cAdwXpdcD3ge+2UfRP3f0UYCJwlpldHLbtCXefEPw8dFRH1A32HggFh/Q+8QBcNKY/y7bsZVd1XTSrJSLSaSJpOUwBSt19g7sfBOYDs1vkmQ08Eiw/BcwwM3P3fe7+JqEgcZi773f3V4Llg8AyYOBxHEe3qtrfQHJCLAlxodN30Zj+ALywamc0qyUi0mkiCQ4FwNaw9W1BWpt53L0RqAKyIqmAmfUFLgVeDku+wsw+NLOnzGxQO/vdYGYlZlZSXl4eyUd1mr0HDtI3Of7w+oi8VAqzknXfQUROGFG9IW1mccAfgF+4+4Yg+S9AobuPA17k0xbJZ7j7g+4+2d0n5+TkdE+FA1UHGsjok3B43cy4aEx/3llfQVXQ5SQi0ptFEhzKgPD/3gcGaW3mCS74GUBFBGU/CKxz9583J7h7hbvXB6sPAadFUE632ru/gb594j+TduGY/jQ2Oa+s2RWlWomIdJ5IgsMSoNjMiswsAZgDLGiRZwFwfbB8JbDI3f1IhZrZjwgFkW+3SM8PW70MWB1BHbtNXcMh6hubyGgRHCYO6ktuWqK6lkTkhNDhE9Lu3mhmNwHPA7HAPHdfaWZ3ACXuvgB4GHjUzEqBPYQCCABmtglIBxLM7HLgQqAa+F/AGmCZmQHcF4xMutnMLgMag7K+1jmH2jmaRyqF33MAiIkxLhidx9PLyqhrOERSfGw0qici0ikimj7D3RcCC1uk/SBsuQ74cjv7FrZTrLWT/3bg9kjqFQ1V+0MPwLXsVoLQqKXHFm/hjXW7uWB0XndXTUSk02hupaPU3HLISP70hvTji7cA0NjURFJ8DL96dT3lNfVcM3VwVOooInK8NH3GUara30CMQVpS67gaFxPDKf3TWbOjmkNNR7zlIiLSoyk4HKW9BxpI7xNPjLXZK8bo/HT2HzzE5gpNxCcivZeCw1EKPePQ+n5DsxF5acTFGCvKqrqxViIinUvB4Sjt3X+wzZvRzRLiYji1IIPlW/fqJUAi0mspOByFJneqDzR+5unotkwryqS+sYln3m/5rKCISO+g4HAUausbOeTe6hmHlgZlJjMgI4lH39lMB88Cioj0SAoORyH8PQ5HYmZMG5rF2p01vLdxT3dUTUSkUyk4HIVPn3E4cnAAGDewL+lJcfz+3c1dXS0RkU6n4HAUmp+OPtJopWYJcTF8ZfIgnv9oB5v0fmkR6WUUHI7C/oOHiDHoE+G8STecPZT42Bh+9uLHXVwzEZHOpeBwFOoaD5EYF4u18wBcS7npScydXsRfPviEj/Tcg4j0IgoOR6GuITR3UqQeX7yFzJQEkhNi+c4Tyw/PwSQi0tMpOByF+mOYijspPpZzR+Swblct63bVdFHNREQ6l4LDUahrbCIx7ujf0zB1aBZZKQn8+f0y9h/UU9Mi0vMpOByF0Et8jv6UxcfG8KVJA6nc38BP/ra2C2omItK5FByOwvG84a0oO4VpQ7N45J1NLNmkB+NEpGdTcDgKdQ1NJMYd+ym7aEweA/v14Z+eXM7e4JkJEZGeSMEhQu5OfePxvRs6MS6We+dMZEdVHTfPX64XAolIjxVRcDCzWWa21sxKzey2NrYnmtkTwfbFZlYYpGeZ2StmVmtm97XY5zQzWxHs8wsLHh4ws0wze9HM1gW/+3XCcR63uoYmmpzjCg4Akwb3447Zp/L6x+X87AXdfxCRnqnD4GBmscD9wMXAaOBqMxvdIttcoNLdhwP3AHcF6XXA94HvtlH0r4C/B4qDn1lB+m3Ay+5eDLwcrEddTV1oXqVjuSHd0tVTBnP1lME88Op6nliiZx9EpOeJ5Eo3BSh19w3ufhCYD8xukWc28Eiw/BQww8zM3fe5+5uEgsRhZpYPpLv7ux6a0/r3wOVtlPVIWHpUVdeFhqAey1DWcI8v3sLji7cwqn8aI/JSue1PK/iXpz7sjCqKiHSaSIJDAbA1bH1bkNZmHndvBKqArA7K3NZOmXnuvj1Y3gHktVWAmd1gZiVmVlJeXh7BYRyfzmw5AMTFxnDNlCEUZqfwx6Vbee7D7R3vJCLSTXr0DemgVdHmXVt3f9DdJ7v75JycnC6vS03Qckg6zpZDuIS4GK6bNoSB/ZK56Q/LeOiNDXo5kIj0CJEEhzJgUNj6wCCtzTxmFgdkABUdlDmwnTJ3Bt1Ozd1PuyKoY5c7HByO84Z0S4nxscydXsSsMf350XOr+bc/f0R946FO/QwRkaMVSXBYAhSbWZGZJQBzgAUt8iwArg+WrwQW+RH+BQ66jarNbFowSuk64Nk2yro+LD2qOrtbKVx8bAz3XzOJb54zlMcWb+GL979NqeZhEpEo6vBKF9xDuAl4HlgNPOnuK83sDjO7LMj2MJBlZqXAPxE2wsjMNgF3A18zs21hI53+AXgIKAXWA38N0u8ELjCzdcDMYD3qauu7puXQbP6SrQzJTOHaaUPYVLGPi+99gxsfW6ZnIUQkKuIiyeTuC4GFLdJ+ELZcB3y5nX0L20kvAU5tI70CmBFJvbpT82ilhON4QjoSo/LTuXlGMc8sK+O5FdvZVrmf//elcYwekN6lnysiEq5H35DuSWrqGkiMiyEmwhf9HI/0pHiuO2MIc04fRNneA1x635vc9bc11DXoXoSIdI+IWg4SuiHdVV1KbTEzxg3sy/DcVP760Q5+9ep6nliylcsnFPCDS1s+gygi0rnUcohQc8uhuyUnxHHFpIHMnV6EAfPe2sitT35A5T5N3CciXUfBIULd3XJoaVhOKjfPKObcETk8u7yMmXe/xrPLy/RchIh0CQWHCNXWN3bJMNajER8bw4Vj+vPfN09nUGYyt8xfztd+u4TNFfuiWi8ROfEoOESopq7xuOdV6izLNu/lytMG8oVx+by7oYIZP3uNbzyyRA/PiUinUXCIUE1dQ1S7lVqKMePMYdl8Z+YIRuWn89LqXcz6+Ru8sa7r55kSkROfgkOEquui363UlvQ+8Vw9ZTBfP6sQgGsffo+bHl/Gzuq6I+8oInIEGsoagfrGQxxsbOpRLYeWinPTKMxK4Y115fztox28uGonM0flce+cCcTF9rygJiI9m64aEfh0RtaefbriY2M4/5Q8bplRzJCsZJ5bsZ3L7nuLZVsqo101EellevbVroeo7aIZWbtKVmoi159RyDVTBrNn30G+9MDb3PGXVRxsbIp21USkl1BwiEBNJ70FrjuZGacWZPDSredw3RlDmPfWRq568B0+2Xsg2lUTkV5AwSECXTldd1dbsPwTTumfztVTBrPqk2pm3v0aP1ywMtrVEpEervdd7aKgupd1K7VlbEEGN547nPSkeB55exN3v7BW04GLSLsUHCLwacuh9wYHgOy0RL51zjAmDe7HLxaVMvv+N/lg695oV0tEeiAFhwj0ltFKkUiIi+GK0wZy/zWT2FVdz+UPvMVtf/qQbZX7o101EelBev/Vrhs0vwUusZe3HMJVHWjgW+cM48yhWfxx6TbO+cmrfPk/39HrSUUE0ENwEampa6BPfCyxMV3/op/ulBQfy+fHDeCs4dm89nE5JZsrmXn365w1PIuvTB7EjFF5pCbqKyJyMtJffgRq6hpJTTpxT1Xf5ARmTyhgxqg8Gg418di7m7ll/nIS42I4d2QO55+Sy3kjc8lNT4p2VUWkm0R0xTOzWcC9QCzwkLvf2WJ7IvB74DSgArjK3TcF224H5gKHgJvd/XkzGwk8EVbEUOAH7v5zM/sh8PdA8wxy/xq8wzpqauoaSTuBg0Oz5lbCP5w3nC0V+/mwrIp3N+zh+ZU7ATi1IJ3zR+Zy6fgBFOelRbOqItLFOrzimVkscD9wAbANWGJmC9x9VVi2uUCluw83sznAXcBVZjYamAOMAQYAL5nZCHdfC0wIK78MeCasvHvc/afHfXSdpLqugbSk+GhXo9vEmFGYnUJhdgqXjstnR3Uda3fUsHZHDb9cVMovFpUyZkA6P7lyHGMGZES7uiLSBSL5d3gKUOruGwDMbD4wGwgPDrOBHwbLTwH3mZkF6fPdvR7YaGalQXnvhO07A1jv7puP50C6Uk1dI+knQcuhLWZGfkYf8jP6cO7IXGrrG3lnfQVvr9/NF375JtefUcj3Zo0kOeHkPD8iJ6pIRisVAFvD1rcFaW3mcfdGoArIinDfOcAfWqTdZGYfmtk8M+vXVqXM7AYzKzGzkvLyrn2HQW39ydGtFInUxDguGJ3H9y46hWunDeF3b2/i4nvfYPGGimhXTUQ6UVSHsppZAnAZ8Mew5F8Bwwh1O20HftbWvu7+oLtPdvfJOTk5XVrPmroG0hJPnm6lSPRJiOWU/ul8Y3oRNXWNXPXgu1z94Lv87q1N0a6aiHSCSIJDGTAobH1gkNZmHjOLAzII3ZjuaN+LgWXuvrM5wd13uvshd28CfkOoGyqqTvTRSsdjaE4qN59fzBnDsnhnQwW/WLSOd9WKEOn1IgkOS4BiMysK/tOfAyxokWcBcH2wfCWwyN09SJ9jZolmVgQUA++F7Xc1LbqUzCw/bPWLwEeRHkxXaDzUxP6Dh9StdAQJcTFcOm4Af/+5oQDMefBdfvDsR+yurY9yzUTkWHV4xXP3RjO7CXie0FDWee6+0szuAErcfQHwMPBocMN5D6EAQpDvSUI3rxuBG939EICZpRAaAfXNFh/5EzObADiwqY3t3ar56eiTabTSsSrKTuHm84vZsmc/v317I394bwuzTs1nzumDmDY064R7iFDkRGahf/B7t8mTJ3tJSUmXlL11z34+95NX+MmV42g81PvPVXe4ZupgSnfV8tjizfxp6Taq6xrJTUvk0vEDuO6MIQzJSol2FUUEMLOl7j65rW3qK+lA86R76Ulx7NnXEOXa9A6PL94ChN5rfeuFI1mzo4YPtu7ld29tYt6bGxmVn865I3MY2C+Za6YOjnJtRaQtCg4daJ6uOy0pXsHhGMTHxjC2IIOxBRlU1zXw7oYKFm/Yw6rt1YwZkM6UokyG56ZGu5oi0oJmZe1Ac8tBE9Adv/SkeC4c3Z9/vmgk55+Sy7pdtVx4z2t876kPKNPrS0V6FF3xOlBT39xy0KnqLEnxscwclce0oVnsqKrjv97dzJ/f/4S/mzaEG88bRlZqYrSrKHLSU8uhA80tB41W6nypiXEMz03l2zOLGTswg9++tZEz7lzE9fPeY3uVWhIi0aTg0IFPg4NaDl2lb3ICV0wayC0zihmRm8rrH5cz/a5XuPGxZbz2cbnedS0SBbridaCmrpGE2Jhe//7o3iA3PYlrpg5hz76DVNc18MSSrTy3Yjv905P40qQCrjxtIENzdPNapDsoOHSgpq5BrYZulpmSQGZKArdeMILVO2pYtrmSX726ngdeXc/phf2YO72IC0b310N1Il1IV70OaF6l6IlrMQx2+Za9LN5Ywbf+axmZKQmcNSyLSUP68fWziqJdVZETjq56HVDLoWdIT4rn7BE5nDU8m1Xbq3lzXTl/+XA7L63exa6aer52ZiF5eo2pSKfRVa8DNXWNmq67B4mNscOtiS0V+3ijdDe/fm09D72xgUvHD+Ab04cyekB6tKsp0uspOHSgpq6RIVnJ0a6GtGFwVgpfzUph+vBs5r21kSdLtvL0sjLOGp7FdWcUMuOUXOJiNSBP5FgoOHQg9BY4tRx6sjdLdzMiL41bLxjJkk17eHv9br756FLy0hO5avIgrpoymIK+faJdTZFeRcGhA9W659Br9EmIPXxfYu2OGpZs2sMvF5Xyy0WljMhL46zh2Xz/C6MIvd5cRI5EV70jaGpyvT+6F4qNMUYPSGf0gHQq9x+kZNMelmyqZN5bG1m8sYIbzh7K58fmq8tJ5Aj013EE+w424q6no3uzfskJXDC6P9+7aCRfmljAgYZD3DJ/Oef8x6s8/OZGKvcdjHYVRXokBYcj0LxKJ4642BgmF2by0nfO4TfXTSY/I4n/+9+rmPLvL3HD70t4dnkZVfs1JbtIM/1LfASaV+nEM3/JVgC+NGkgZwzL4v0te3lnfQUvrNpJbIwxeUg/Zo7KY+boPIqy9cY6OXnpqncEtfWfvuhHTjz5GX3IH9uHWaf2p6zyAKt3VLNmew0/XriaHy9czeDMZP7x/OFcOn6A5taSk05E3UpmNsvM1ppZqZnd1sb2RDN7Iti+2MwKw7bdHqSvNbOLwtI3mdkKM1tuZiVh6Zlm9qKZrQt+9zvOYzxm1Wo5nBRizBiUmcyFo/tz84xi/vmikVxyan8OHDzEPz/1Ief8xys8uWSrZoeVk0qHwcHMYoH7gYuB0cDVZja6Rba5QKW7DwfuAe4K9h0NzAHGALOAB4Lymp3n7hNavOD6NuBldy8GXg7WoyL8/dFy8uiXnMD04hy+PbOYudOLSIiN4Xt/+pCz7lzEvz+3OtrVE+kWkbQcpgCl7r7B3Q8C84HZLfLMBh4Jlp8CZlhoMPlsYL6717v7RqA0KO9Iwst6BLg8gjp2ieb3R6dq+oyTkpkxLCeVb50zjKunDKau4RAPvrGBf3nqQ41ykhNeJMGhANgatr4tSGszj7s3AlVAVgf7OvCCmS01sxvC8uS5+/ZgeQeQ11alzOwGMysxs5Ly8vIIDuPo6Ya0QChIjC3I4JaZxXyuOJunlm1jxt2v8dTSbbirq0lOTNEcyjrd3ScR6q660czObpnBQ395bf71ufuD7j7Z3Sfn5OR0SQVr6hqIjTGSE3QzUiAxLpaLT83nuZunU5Sdwnf/+AFf+fU7vL+lMtpVE+l0kQSHMmBQ2PrAIK3NPGYWB2QAFUfa192bf+8CnuHT7qadZpYflJUP7Ir8cDpXbV0jqYlxmm5BPmPZ5r18cWIBX5xYwOrtNXzxgbf5/C/eYEN5bbSrJtJpIgkOS4BiMysyswRCN5gXtMizALg+WL4SWBT8178AmBOMZioCioH3zCzFzNIAzCwFuBD4qI2yrgeePbZDO341dZo6Q9oWY8bphZnceuEIZpySy7qdtVx4z+v8259XsKumLtrVEzluHV753L3RzG4CngdigXnuvtLM7gBK3H0B8DDwqJmVAnsIBRCCfE8Cq4BG4EZ3P2RmecAzwX/kccDj7v634CPvBJ40s7nAZuArnXi8R6W6TjOyypElxsUyY1QeU4oy2VZ5gMff28IfS7bx1alD+OY5Q/UCIum17ES4oTZ58mQvKSnpOONRuurX7+AOT37rDAAeX7yl0z9DTiwVtfW8snYXy7fuxTA+Py6fa6YOZmpRpronpccxs6UtHiU4TH0mR1BT10h+hv7zk8hlpSZy5WmDOG9kLm9vqODVtbtY8MEnFPTtw8Wn9ueScflMGNiXmBgFCunZFByOoKa+gRFJqdGuhvRCWamJXDpuABeN7s/KT6pYUVbFb9/exENvbiSjTzxXTBrIJWP7M2lwPwUK6ZEUHI6gVvcc5DglxMUwcXA/Jg7uR13DIVZvr+ajsir+693NzHtrI/3Tk7h0fD5fmTyI4ry0aFdX5DAFh3a4u0YrSadKio/9TKBYs6OaFduqePjNjfzmjY0M6teHfzhvOF8Yl69/SiTqdOVrR11DE41Nrj9S6RJJ8bFMGNSPCYP6UVPXwPKteynZXMntT6/gjr+s4pKx+Vx1+iBOL+ynG9kSFQoO7Tg8r5JaDtLF0pLi+VxxDtOHZ7O18gBLN+/hvz/8hD8t20ZOaiLfuWAEX5pUoGnDpVvpyteOas3IKt3MzBicmczgzGQ+P3YAH5VV8faG3fzrMyv46Qtr+cbnirjujEJSE/WdlK6nb1k7mlsOuucg0ZAQF8OkIf2YOLgvw3JT+c/X1vOTv63lwdc38I3pRVx/ZqG6PKVL6R3S7ajW+6OlBzAzNpTv48LR/fmf5wyjf3oSP33hY07/8Uvc+9I6qg7ovdfSNRQc2lFRWw9AVkpClGsiEjIoM5nrzijkxnOHU5Sdyj0vfcz0uxZxz4sfU7VfQUI6l4JDO3YHwSE7LTHKNRH5rIJ+fbh22hCeu3k6Zw7L4t6X1zH9rkX87IW17NFLiKSTqEO9HbtrD5IQF0Oabv5JD/XB1irOGZHLiLw0Xlmzi18uKuWBV9ZzzsgcLh2fz8xReeoWlWOmK187dtfUk5OaqDHm0uPlZ/ThmqlD2Fldx7LNlazZXs2iNbtIiIvhvJE5XDI2n3NH5JKRrEAhkVNwaEd5bT3ZqbrfIL1HXnoSF4/Np8mdrXv28+G2Kt4ureD5lTuJjTFOL+zHzFF5zBiVR1F2SrSrKz2cgkM7KmoPakZW6ZVizBiSlcKQrBQ+Py6fbZUHiI2Bl1fv4kfPreZHz62moG8fpg7NZFpRFlOHZjI4M1mtZPkMBYd27K6tZ2xBRrSrIXJcYoIH6wCuO6OQyn0HWbOzho3ltTz/0Q6eXhZ6429+RhJTizKZOjSLaUOzKMxSsDjZKTi0oanJqdh3kOw0dSvJiaVfSgJnDM3ijKFZuDu7aurZuHsfG3fv46XVu/jz8k8AyE1LZPrwbL4wPp/pw3NIiNPAxpONgkMb9h5o4FCTk52qYaxy4jIz8tKTyEtPYloQLMprPw0Wf/1oB0+/X0af+FimFGXys6+M19/ESUTBoQ2Hn3HQH4KcRMyM3LQkctOSmFqURWNTE6U7a1m6pZLXPy7nrDsX8dWpQ7h5xnD6JqtVfaKLqK1oZrPMbK2ZlZrZbW1sTzSzJ4Lti82sMGzb7UH6WjO7KEgbZGavmNkqM1tpZreE5f+hmZWZ2fLg55JOOM6jsrtGwUEkLiaGU/LT+erUIXxn5gguGz+A3729kXN/+iq/e2sjDYeaol1F6UIdthzMLBa4H7gA2AYsMbMF7r4qLNtcoNLdh5vZHOAu4CozGw3MAcYAA4CXzGwE0Ajc6u7LzCwNWGpmL4aVeY+7/7SzDvJolQcthxzdcxABQjMFZKcl0j8jiYUrtvPDv6zi/lfWc8nYfP7P7DHRrp50gUhaDlOAUnff4O4HgfnA7BZ5ZgOPBMtPATMsNNRhNjDf3evdfSNQCkxx9+3uvgzA3WuA1UDB8R9O59hdG5qCQC0Hkc/Kz+jD/ziriGunDaHJnUfe2cRVv36Ht0p34+7Rrp50okiCQwGwNWx9G60v5IfzuHsjUAVkRbJv0AU1EVgclnyTmX1oZvPMrF9blTKzG8ysxMxKysvLIziMyO2urSc+1sjooydKRVoyM0blp3PLzGK+MC6fjbv38dWHFnP5A28z/70th6e7l94tquPTzCwV+BPwbXevDpJ/BQwDJgDbgZ+1ta+7P+juk919ck5OTqfWa3dNPVkpmjpD5EjiYmI4c1g2r3/vPP7v7DHsq2/ktqdXMOXHL/MPjy3l2eVlChS9WCSjlcqAQWHrA4O0tvJsM7M4IAOoONK+ZhZPKDA85u5PN2dw953Ny2b2G+C/Iz2YzrK7tl7POIhE6OllZcTGxPD1MwvZVnkgGN20m4UrdpAQG8P04mxmjenPzNF5ZGoK/F4jkuCwBCg2syJCF/Y5wDUt8iwArgfeAa4EFrm7m9kC4HEzu5vQDeli4L3gfsTDwGp3vzu8IDPLd/ftweoXgY+O7dCO3e7ag7rfIHKUzIxBmckMykzmsvED2LpnPys/qeb9LZUsWrML+xNMG5rFjFG5nDMih+G5qWqd92AdBgd3bzSzm4DngVhgnruvNLM7gBJ3X0DoQv+omZUCewgFEIJ8TwKrCI1QutHdD5nZdOBaYIWZLQ8+6l/dfSHwEzObADiwCfhmpx1thHbX1jOyf1p3f6zICSN8fqeLT+3P9qo6Vn5SxbbKA4fnd8rPSOKcETmcPSKHs4Zla9bYHiaih+CCi/bCFmk/CFuuA77czr4/Bn7cIu1NoM1/Gdz92kjq1FXcnQq1HEQ6jZkxoG8fBvTtA8De/QdZt7OWj3fV8OflZcxfspUYgwmD+nJ2ECzGD+xLbIxaFdGkJ6RbqD7QyMFDTZquW6SL9E1O4PSiTE4vyuRQk7Otcj8f76xl3a4a7n1pHT9/aR3JCbGMG9iX/3XJKE4tSFf3UxQoOLRQrqkzRLpNbMyn3U8XjM5jf30jpeW1rPykmpJNe7j0vjcZmZfGFacVcPnEAnLTNI1+d1FwaEHzKolET3JiHOMG9mXcwL4cOHiIFWVVLNtSyb8vXMOdf11DcW4aN88oZsaoXJLiY6Nd3ROagkMLh4ODhrKKRFWfhNBssFOKMimvqef9LZW8v3UvNz6+jIw+8Vw2fgBXnDaQ8QMz1O3UBRQcWqjQ1BkiPU5OWiIXBs9KrC+vZdnmSv7w3hYefXczOWmJnDa4H3ddOU6zGnQiBYcWdtfWE2PQT1MSi/Q4MWYU56ZRnJtGXUPQ7bS5kr+t3MGbpbv56rTBzD2riNx03Zs4XgoOLeyurSczJVHD6ER6uKT4WE4vzOT0wkw+2XuAzXv285vXN/DbNzdxxWkD+ebZQynMTol2NXstBYcWNlfsZ0Bf/dch0ps0P0cxIjeVN0p388eSrcx/bwvjB/XlP64cR3GeHmo9WnoxbJhDTc4HW/cyfmDfaFdFRI5BVmoil08o4LsXjWT68GxWfVLNBfe8ztd/+x6vf1yuacWPgloOYdbtqmHfwUNMHNw32lURkeOQnhTPxWPzOXtEDvsONvJf727hunnvMSQrmcsnFPDFiQXqcuqAgkOY97fsBWDi4DZfISEivUxKYhwpiXHcfP5wVpRVsXRLJb94eR33vryO4txUzh+Vy4xT8pg0uC9xsepICafgEGb5lr30TY6nMCs52lURkU4UFxvDxMH9mDi4H1UHGkiIi2HRmp08/MZGfv3aBvomx3PuiBzOH5XHOSNyNCQWBYfPeH9rJRMH9dUDNSInsOYL/+fHDmDGKXms21XLmu3VvLBqJ39e/gmxMcbphf2YOSqPGaPyKDpJu58UHALVdQ2s21XLF8YNiHZVRKSbJMXHMrYgg7EFGTS5s23PflbvqGHNjurDU4sPzU5hxqhcZozKY/KQfidN95OCQ+DDrVW4o5vRIiepGDMGZ6UwOCuFi8b0p3LfQdbsqGbvgQZ+9/YmfvPGRjL6xHPuyBzOPyWXc0fkntDvoFBwCLy/pRIzGD+ob7SrIiI9QL+UBM4Ylg3A+SNzQ91PO6p5cdVOnm3R/XT+KbkMzUmNco07l4JD4P2texmek0p60on7n4CIHJvE+FhOLcjg1LDup5gY4+XVu07Y7icFB6CpyXl/SyUXjM6LdlVEpIdr7n4CuP7MwsPdT2t21DDvrVD3U3pSHOeOzGXGqN7b/aTgANz78joq9zdwzojcaFdFRHqZ5u6nM4ZlU99wKOh+quHl1TtZ8MEnxBhMKcrkvJG5nDU8m1H56b1i7raIgoOZzQLuBWKBh9z9zhbbE4HfA6cBFcBV7r4p2HY7MBc4BNzs7s8fqUwzKwLmA1nAUuBadz94fIfZvr99tIN7X17HlacN5JKx/bvqY0TkJNBW99OaHTXsqK7j//11DRAaSjttaCZnDsvm9MJMRvZP65HBosPgYGaxwP3ABcA2YImZLXD3VWHZ5gKV7j7czOYAdwFXmdloYA4wBhgAvGRmI4J92ivzLuAed59vZv8ZlP2rzjjYlj7eWcOtTy5n/KC+/OjyU/V8g4h0mvDRTxAaLr+hfB/ry2tZvHEPz6/cCUBKQixjCjIYmZdGcV4qA/v1ITcticyUBJLiY0mMiyEpPvYzAcTdafLQfHCxMdYlwSWSlsMUoNTdNwCY2XxgNhAeHGYDPwyWnwLus9CVdjYw393rgY1mVhqUR1tlmtlq4HzgmiDPI0G5XRIc3irdTXJiHL/+u9P0ykER6VLpSfFMGNSXCcGIyD37DrJlzz627DnAJ3sP8MHWvdQ3NrW7f1yMYRYKCE1h8wf+6PJT+btpQzq9vpEEhwJga9j6NmBqe3ncvdHMqgh1CxUA77bYtyBYbqvMLGCvuze2kf8zzOwG4IZgtdbM1kZwLG3K/7eIs2YDu4/1c05wOjft07lpm85L+yI+N9feBdce++e0G1V67Q1pd38QeLA7P9PMStx9cnd+Zm+hc9M+nZu26by0ryecm0gG4pYBg8LWBwZpbeYxszggg9CN6fb2bS+9AugblNHeZ4mISBeLJDgsAYrNrMjMEgjdYF7QIs8C4Ppg+UpgkYfeqrEAmGNmicEopGLgvfbKDPZ5JSiDoMxnj/3wRETkWHTYrRTcQ7gJeJ7QsNN57r7SzO4AStx9AfAw8Ghww3kPoYs9Qb4nCd28bgRudPdDAG2VGXzkvwDzzexHwPtB2T1Ft3Zj9TI6N+3TuWmbzkv7on5uTK/NExGRlnr35B8iItIlFBxERKQVBYcImdksM1trZqVmdlu06xNNZrbJzFaY2XIzKwnSMs3sRTNbF/w+KV7EbWbzzGyXmX0UltbmubCQXwTfoQ/NbFL0at712jk3PzSzsuC7s9zMLgnbdntwbtaa2UXRqXXXM7NBZvaKma0ys5VmdkuQ3qO+NwoOEQibQuRiYDRwdTA1yMnsPHefEDYW+zbgZXcvBl4O1k8GvwNmtUhr71xcTGjEXjGhBzi75Mn/HuR3tD43EJoeZ0LwsxCgxVQ7s4AHgr+7E1EjcKu7jwamATcGx9+jvjcKDpE5PIVIMAlg8xQi8qnZhKY7Ifh9efSq0n3c/XVCI/TCtXcuZgO/95B3CT3Tk98tFY2Cds5New5PtePuG4HwqXZOKO6+3d2XBcs1wGpCM0H0qO+NgkNk2ppCpM1pPU4SDrxgZkuDaUwA8tx9e7C8AziZX47R3rnQ9yjkpqB7ZF5Y9+NJeW7MrBCYCCymh31vFBzkWEx390mEmrs3mtnZ4RuDhxk1Rhqdizb8ChgGTAC2Az+Lam2iyMxSgT8B33b36vBtPeF7o+AQmUimEDlpuHtZ8HsX8Ayh5v/O5qZu8HtX9GoYde2di5P+e+TuO939kLs3Ab/h066jk+rcmFk8ocDwmLs/HST3qO+NgkNkIplC5KRgZilmlta8DFwIfMRnp1A52ac9ae9cLACuC0afTAOqwroRTgot+sq/SOi7A+1PtXPCCV5n8DCw2t3vDtvUo743vXZW1u7U3hQiUa5WtOQBz4S+38QBj7v738xsCfCkmc0FNgNfiWIdu42Z/QE4F8g2s23A/wbupO1zsRC4hNDN1v3A17u9wt2onXNzrplNINRlsgn4Jhx5qp0T0FmEZtleYWbLg7R/pYd9bzR9hoiItKJuJRERaUXBQUREWlFwEBGRVhQcRESkFQUHERFpRcFBRERaUXAQEZFW/j9COVxsWRkuDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = np.concatenate(all_times[1])\n",
    "sns.distplot(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:26:45.474115Z",
     "start_time": "2021-10-14T02:26:45.457161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.       , 47.88739  , 93.00654  , ..., 11.193436 , 46.539505 ,\n",
       "        3.1424942], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_val = times[sorted_index]\n",
    "t_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:32:11.526361Z",
     "start_time": "2021-10-14T02:32:10.569979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25304bcbec8>]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#11\n",
    "\n",
    "\n",
    "times = np.concatenate(all_times[0])\n",
    "k_val = np.concatenate(kernels[1])\n",
    "sorted_index = np.argsort(times)\n",
    "t_val = times[sorted_index]\n",
    "k_val = k_val[sorted_index]\n",
    "\n",
    "\n",
    "moving_average = 100\n",
    "\n",
    "## Moving Average \n",
    "k_val = np.convolve(k_val, np.ones(moving_average), 'valid') / moving_average    \n",
    "t_val = np.convolve(t_val, np.ones(moving_average), 'valid') / moving_average\n",
    "\n",
    "plt.plot(t_val,k_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T03:09:42.312627Z",
     "start_time": "2021-10-14T03:09:42.292674Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('data/mimic/test_manifold_format.pkl', 'rb') as f:\n",
    "    loaded_hawkes_data = pickle.load(f)\n",
    "\n",
    "\n",
    "test_seq_times, test_seq_types, test_seq_lengths, _ = process_loaded_sequences(loaded_hawkes_data, 75)\n",
    "\n",
    "test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "test_seq_times = test_seq_times[reorder_indices_test]\n",
    "test_seq_types = test_seq_types[reorder_indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T03:13:25.943498Z",
     "start_time": "2021-10-14T03:13:25.909400Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SAHP:\n\tsize mismatch for type_emb.weight: copying a param with shape torch.Size([76, 32]) from checkpoint, the shape in current model is torch.Size([76, 16]).\n\tsize mismatch for position_emb.div_term: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for position_emb.Wt.weight: copying a param with shape torch.Size([16, 1]) from checkpoint, the shape in current model is torch.Size([8, 1]).\n\tsize mismatch for attention.linear_layers.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.linear_layers.1.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.linear_layers.2.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.output_linear.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.output_linear.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for feed_forward.w_1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([64, 16]).\n\tsize mismatch for feed_forward.w_1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for feed_forward.w_2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).\n\tsize mismatch for feed_forward.w_2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for input_sublayer.norm.a_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for input_sublayer.norm.b_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for output_sublayer.norm.a_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for output_sublayer.norm.b_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for start_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for start_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for converge_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for converge_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decay_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decay_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for intensity_layer.0.weight: copying a param with shape torch.Size([75, 32]) from checkpoint, the shape in current model is torch.Size([75, 16]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-d280a6f9dcb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sahp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m34\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprocess_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models/sahp-mimic_hidden16-20211012-005042'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1407\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1408\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SAHP:\n\tsize mismatch for type_emb.weight: copying a param with shape torch.Size([76, 32]) from checkpoint, the shape in current model is torch.Size([76, 16]).\n\tsize mismatch for position_emb.div_term: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for position_emb.Wt.weight: copying a param with shape torch.Size([16, 1]) from checkpoint, the shape in current model is torch.Size([8, 1]).\n\tsize mismatch for attention.linear_layers.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.linear_layers.1.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.linear_layers.2.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.output_linear.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.output_linear.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for feed_forward.w_1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([64, 16]).\n\tsize mismatch for feed_forward.w_1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for feed_forward.w_2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).\n\tsize mismatch for feed_forward.w_2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for input_sublayer.norm.a_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for input_sublayer.norm.b_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for output_sublayer.norm.a_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for output_sublayer.norm.b_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for start_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for start_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for converge_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for converge_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decay_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decay_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for intensity_layer.0.weight: copying a param with shape torch.Size([75, 32]) from checkpoint, the shape in current model is torch.Size([75, 16])."
     ]
    }
   ],
   "source": [
    "\n",
    "model = train_sahp.make_model(max_sequence_length=34,process_dim=75)\n",
    "model_dict =torch.load('saved_models/sahp-mimic_hidden16-20211012-005042',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T03:06:37.030952Z",
     "start_time": "2021-10-14T03:06:37.026963Z"
    }
   },
   "outputs": [],
   "source": [
    "### StackOverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T22:05:35.767157Z",
     "start_time": "2021-06-23T22:04:35.091720Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load Data Set\n",
    "dataset = 'retweet'\n",
    "process_dim =3 \n",
    "\n",
    "train_path = 'data/' + dataset + '/train_manifold_format.pkl'\n",
    "dev_path = 'data/' + dataset + '/dev_manifold_format.pkl'\n",
    "test_path = 'data/' + dataset + '/test_manifold_format.pkl'\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    train_hawkes_data = pickle.load(f)\n",
    "with open(dev_path, 'rb') as f:\n",
    "    dev_hawkes_data = pickle.load(f)\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_hawkes_data = pickle.load(f)\n",
    "\n",
    "train_seq_times, train_seq_types, train_seq_lengths, train_tmax = \\\n",
    "process_loaded_sequences(train_hawkes_data, process_dim)\n",
    "dev_seq_times, dev_seq_types, dev_seq_lengths, dev_tmax = \\\n",
    "process_loaded_sequences(dev_hawkes_data, process_dim)\n",
    "test_seq_times, test_seq_types, test_seq_lengths, test_tmax = \\\n",
    "process_loaded_sequences(test_hawkes_data, process_dim)\n",
    "\n",
    "tmax = max([train_tmax, dev_tmax, test_tmax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T22:07:33.676349Z",
     "start_time": "2021-06-23T22:07:33.642195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample size: 20000\n",
      "Dev sample size: 2000\n",
      "Test sample size: 2000\n",
      "No. of event tokens in training subset: tensor(2176116)\n",
      "No. of event tokens in development subset: tensor(215521)\n",
      "No. of event tokens in test subset: tensor(218465)\n",
      "max_sequence_length: 264\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "train_sample_size = train_seq_times.size(0)\n",
    "print(\"Train sample size: {}\".format(train_sample_size))\n",
    "\n",
    "dev_sample_size = dev_seq_times.size(0)\n",
    "print(\"Dev sample size: {}\".format(dev_sample_size))\n",
    "\n",
    "test_sample_size = test_seq_times.size(0)\n",
    "print(\"Test sample size: {}\".format(test_sample_size))\n",
    "\n",
    "\n",
    "# Define training data\n",
    "train_seq_times = train_seq_times.to(device)\n",
    "train_seq_types = train_seq_types.to(device)\n",
    "train_seq_lengths = train_seq_lengths.to(device)\n",
    "print(\"No. of event tokens in training subset:\", train_seq_lengths.sum())\n",
    "\n",
    "# Define development data\n",
    "dev_seq_times = dev_seq_times.to(device)\n",
    "dev_seq_types = dev_seq_types.to(device)\n",
    "dev_seq_lengths = dev_seq_lengths.to(device)\n",
    "print(\"No. of event tokens in development subset:\", dev_seq_lengths.sum())\n",
    "\n",
    "# Define test data\n",
    "test_seq_times = test_seq_times.to(device)\n",
    "test_seq_types = test_seq_types.to(device)\n",
    "test_seq_lengths = test_seq_lengths.to(device)\n",
    "print(\"No. of event tokens in test subset:\", test_seq_lengths.sum())\n",
    "\n",
    "\n",
    "## sequence length\n",
    "train_seq_lengths, reorder_indices_train = train_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "train_seq_times = train_seq_times[reorder_indices_train]\n",
    "train_seq_types = train_seq_types[reorder_indices_train]\n",
    "#\n",
    "dev_seq_lengths, reorder_indices_dev = dev_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "dev_seq_times = dev_seq_times[reorder_indices_dev]\n",
    "dev_seq_types = dev_seq_types[reorder_indices_dev]\n",
    "\n",
    "test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "test_seq_times = test_seq_times[reorder_indices_test]\n",
    "test_seq_types = test_seq_types[reorder_indices_test]\n",
    "\n",
    "max_sequence_length = max(train_seq_lengths[0], dev_seq_lengths[0], test_seq_lengths[0])\n",
    "print('max_sequence_length: {}'.format(max_sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:51:59.795188Z",
     "start_time": "2021-10-14T02:51:59.762593Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'replicated_models/sahp-retweet_hidden16-20210623-055702'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-a33ef28e103a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sahp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'replicated_models/sahp-retweet_hidden16-20210623-055702'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'replicated_models/sahp-retweet_hidden16-20210623-055702'"
     ]
    }
   ],
   "source": [
    "model = train_sahp.make_model(max_sequence_length=max_sequence_length+1, process_dim=3)\n",
    "model_dict =torch.load('replicated_models/sahp-retweet_hidden16-20210623-055702',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "batch_size = 32\n",
    "test_size = test_seq_times.size(0)\n",
    "device = 'cpu'\n",
    "test_loop_range = list(range(0, test_size, batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:55:13.604796Z",
     "start_time": "2021-10-14T02:55:06.420326Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 400/400 [00:06<00:00, 58.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 2.4303113130436818\n",
      "Type prediction score: 0.2825\n",
      "tensor(0.0201)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Get test Loss\n",
    "test_event_num, epoch_test_loss = eval_sahp(batch_size, [1,2], test_seq_lengths, test_seq_times,\n",
    "                                            test_seq_types, model, device, 0)\n",
    "\n",
    "test_loss = epoch_test_loss/test_event_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T22:27:37.599244Z",
     "start_time": "2021-06-23T22:27:37.584277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.04366"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(incr_errors[keep_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T03:51:48.073185Z",
     "start_time": "2021-07-28T03:51:47.915135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size: 4000\n",
      "Train sample size: 3200/4000\n",
      "Dev sample size: 400/4000\n",
      "No. of event tokens in training subset: tensor(498611)\n",
      "No. of event tokens in development subset: tensor(63349)\n",
      "No. of event tokens in test subset: tensor(61657)\n",
      "max_sequence_length: 323\n",
      "the number of trainable parameters: 4186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SAHP(\n",
       "  (gelu): GELU()\n",
       "  (type_emb): TypeEmbedding(3, 16, padding_idx=2)\n",
       "  (position_emb): BiasedPositionalEmbedding(\n",
       "    (Wt): Linear(in_features=1, out_features=8, bias=False)\n",
       "  )\n",
       "  (attention): MultiHeadedAttention(\n",
       "    (linear_layers): ModuleList(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (output_linear): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (attention): Attention()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (feed_forward): PositionwiseFeedForward(\n",
       "    (w_1): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (w_2): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation): GELU()\n",
       "  )\n",
       "  (input_sublayer): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (output_sublayer): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (start_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): GELU()\n",
       "  )\n",
       "  (converge_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): GELU()\n",
       "  )\n",
       "  (decay_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): Softplus(beta=10.0, threshold=20)\n",
       "  )\n",
       "  (intensity_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "    (1): Softplus(beta=1.0, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_dim = 2\n",
    "device = 'cpu'\n",
    "train_ratio = 0.8\n",
    "lr = 5e-5\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "with open('data/simulated/hawkes_synthetic_random_2d_20191130-180837.pkl', 'rb') as f:\n",
    "    loaded_hawkes_data = pickle.load(f)\n",
    "    \n",
    "process_dim = loaded_hawkes_data['process_dim'] if 'process_dim' in loaded_hawkes_data.keys() else process_dim\n",
    "\n",
    "seq_times, seq_types, seq_lengths, _ = process_loaded_sequences(loaded_hawkes_data, process_dim)\n",
    "\n",
    "seq_times = seq_times.to(device)\n",
    "seq_types = seq_types.to(device)\n",
    "seq_lengths = seq_lengths.to(device)\n",
    "\n",
    "total_sample_size = seq_times.size(0)\n",
    "print(\"Total sample size: {}\".format(total_sample_size))\n",
    "\n",
    "train_size = int(train_ratio * total_sample_size)\n",
    "dev_ratio = 0.1\n",
    "dev_size = int(dev_ratio * total_sample_size)\n",
    "print(\"Train sample size: {:}/{:}\".format(train_size, total_sample_size))\n",
    "print(\"Dev sample size: {:}/{:}\".format(dev_size, total_sample_size))\n",
    "\n",
    "# Define training data\n",
    "train_seq_times = seq_times[:train_size]\n",
    "train_seq_types = seq_types[:train_size]\n",
    "train_seq_lengths = seq_lengths[:train_size]\n",
    "print(\"No. of event tokens in training subset:\", train_seq_lengths.sum())\n",
    "\n",
    "# Define development data\n",
    "dev_seq_times = seq_times[train_size:train_size + dev_size]  # train_size+dev_size\n",
    "dev_seq_types = seq_types[train_size:train_size + dev_size]\n",
    "dev_seq_lengths = seq_lengths[train_size:train_size + dev_size]\n",
    "print(\"No. of event tokens in development subset:\", dev_seq_lengths.sum())\n",
    "\n",
    "test_seq_times = seq_times[-dev_size:]\n",
    "test_seq_types = seq_types[-dev_size:]\n",
    "test_seq_lengths = seq_lengths[-dev_size:]\n",
    "\n",
    "print(\"No. of event tokens in test subset:\", test_seq_lengths.sum())\n",
    "\n",
    "## sequence length\n",
    "train_seq_lengths, reorder_indices_train = train_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "train_seq_times = train_seq_times[reorder_indices_train]\n",
    "train_seq_types = train_seq_types[reorder_indices_train]\n",
    "#\n",
    "dev_seq_lengths, reorder_indices_dev = dev_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "dev_seq_times = dev_seq_times[reorder_indices_dev]\n",
    "dev_seq_types = dev_seq_types[reorder_indices_dev]\n",
    "\n",
    "test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "test_seq_times = test_seq_times[reorder_indices_test]\n",
    "test_seq_types = test_seq_types[reorder_indices_test]\n",
    "\n",
    "max_sequence_length = max(train_seq_lengths[0], dev_seq_lengths[0], test_seq_lengths[0])\n",
    "print('max_sequence_length: {}'.format(max_sequence_length))\n",
    "\n",
    "\n",
    "d_model = 16\n",
    "atten_heads = 1\n",
    "dropout = 0.1\n",
    "\n",
    "model = make_model(nLayers=1, d_model=d_model, atten_heads=atten_heads,\n",
    "                   dropout=dropout, process_dim=process_dim, device=device, pe='add',\n",
    "                   max_sequence_length=max_sequence_length + 1).to(device)\n",
    "\n",
    "print(\"the number of trainable parameters: \" + str(count_parameters(model)))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=3e-4)\n",
    "model_opt = NoamOpt(d_model, 1, 100, initial_lr=lr, optimizer=optimizer)\n",
    "\n",
    "\n",
    "## Size of the traing dataset\n",
    "train_size = train_seq_times.size(0)\n",
    "dev_size = dev_seq_times.size(0)\n",
    "test_size = test_seq_times.size(0)\n",
    "tr_loop_range = list(range(0, train_size, batch_size))\n",
    "de_loop_range = list(range(0, dev_size, batch_size))\n",
    "test_loop_range = list(range(0, test_size, batch_size))\n",
    "\n",
    "last_dev_loss = 0.0\n",
    "early_step = 0\n",
    "\n",
    "random_seeds = list(range(0, 1000))\n",
    "random.shuffle(random_seeds)\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:03:13.623046Z",
     "start_time": "2021-07-28T04:03:13.523347Z"
    }
   },
   "outputs": [],
   "source": [
    "i_batch = 0\n",
    "model_opt.optimizer.zero_grad()\n",
    "\n",
    "batch_onehot, batch_seq_times, batch_dt, batch_seq_types, _, _, _, batch_seq_lengths = \\\n",
    "    get_batch(batch_size, i_batch, model, train_seq_lengths, train_seq_times, train_seq_types,\n",
    "                   rnn=False)\n",
    "\n",
    "batch_seq_types = batch_seq_types[:, 1:]\n",
    "\n",
    "masked_seq_types = MaskBatch(batch_seq_types, pad=model.process_dim,\n",
    "                             device=device)  # exclude the first added even\n",
    "model.forward(batch_dt, masked_seq_types.src, masked_seq_types.src_mask)\n",
    "# nll = model.compute_loss(batch_seq_times, batch_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:22:55.043265Z",
     "start_time": "2021-07-28T04:22:55.020327Z"
    }
   },
   "outputs": [],
   "source": [
    "### Loss Function\n",
    "def compute_loss(model,seq_times,seq_onehot_types,n_mc_samples = 20):\n",
    "    dt_seq = seq_times[:, 1:] - seq_times[:, :-1]\n",
    "    cell_t = model.state_decay(model.converge_point, model.start_point, model.omega, dt_seq[:, :, None])\n",
    "\n",
    "    n_batch = seq_times.size(0)\n",
    "    n_times = seq_times.size(1) - 1\n",
    "    device = dt_seq.device\n",
    "    # Get the intensity process\n",
    "    intens_at_evs = model.intensity_layer(cell_t)\n",
    "    \n",
    "    \n",
    "    log_intensities = intens_at_evs.log()  # log intensities\n",
    "    log_intensities =  log_intensities*seq_onehot_types[:, 1:, :].sum(dim=-1).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    seq_mask = seq_onehot_types[:, 1:]\n",
    "    log_sum = (log_intensities * seq_mask).sum(dim=(2, 1)) \n",
    "    \n",
    "    \n",
    "    taus = torch.rand(n_batch, n_times, 1, n_mc_samples).to(device) \n",
    "    taus = dt_seq[:, :, None, None] * taus \n",
    "    \n",
    "    \n",
    "    cell_tau = model.state_decay(\n",
    "    model.converge_point[:, :, :, None],\n",
    "    model.start_point[:, :, :, None],\n",
    "    model.omega[:, :, :, None],\n",
    "    taus)\n",
    "    \n",
    "    cell_tau = cell_tau.transpose(2, 3)\n",
    "    intens_at_samples = model.intensity_layer(cell_tau).transpose(2, 3)\n",
    "    intens_at_samples = intens_at_samples*seq_onehot_types[:, 1:, :].sum(dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    total_intens_samples = intens_at_samples.sum(dim=2)  # shape batch * N * MC\n",
    "    partial_integrals = dt_seq * total_intens_samples.mean(dim=2)\n",
    "\n",
    "    integral_ = partial_integrals.sum(dim=1)\n",
    "\n",
    "    res = torch.sum(- log_sum + integral_)\n",
    "    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Other 2-D Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:26:54.485162Z",
     "start_time": "2021-07-28T04:26:54.429348Z"
    }
   },
   "outputs": [],
   "source": [
    "process_dim = 2\n",
    "device = 'cpu'\n",
    "train_ratio = 0.8\n",
    "lr = 5e-5\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "with open('data/simulated/hawkes_2d.pkl', 'rb') as f:\n",
    "    loaded_hawkes_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:27:03.049518Z",
     "start_time": "2021-07-28T04:27:03.044531Z"
    }
   },
   "outputs": [],
   "source": [
    "process_dim = loaded_hawkes_data['process_dim'] if 'process_dim' in loaded_hawkes_data.keys() else process_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:27:06.097620Z",
     "start_time": "2021-07-28T04:27:06.090606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
