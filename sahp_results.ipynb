{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:34:05.084012Z",
     "start_time": "2021-10-14T06:34:03.008107Z"
    }
   },
   "outputs": [],
   "source": [
    "from train_functions import train_sahp\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from utils.load_synth_data import process_loaded_sequences\n",
    "from utils.util import get_batch,count_parameters\n",
    "from utils.atten_optimizer import NoamOpt\n",
    "from train_functions.train_sahp import make_model,eval_sahp,prediction_evaluation,MaskBatch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import evaluation\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "\n",
    "def get_pairwise_times(event_time):\n",
    "    xt_bar = event_time.unsqueeze(1). \\\n",
    "        expand(event_time.size(0), event_time.size(1), event_time.size(1))\n",
    "    xt = xt_bar.transpose(1, 2)\n",
    "    return (xt_bar, xt)\n",
    "\n",
    "\n",
    "def get_pairwise_type_embeddings(embeddings):\n",
    "    xd_bar = embeddings.unsqueeze(1).expand(embeddings.size(\n",
    "        0), embeddings.size(1), embeddings.size(1), embeddings.size(-1))\n",
    "    xd = xd_bar.transpose(1, 2)\n",
    "\n",
    "    return (xd_bar, xd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synth Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:03:28.189301Z",
     "start_time": "2021-10-14T04:03:28.002743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_sequence_length: 323\n"
     ]
    }
   ],
   "source": [
    "model = train_sahp.make_model(max_sequence_length=324)\n",
    "model_dict =torch.load('saved_models/sahp-synthetic_hidden16-20210622-205430',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "with open('data/simulated/hawkes_synthetic_random_2d_20191130-180837.pkl', 'rb') as f:\n",
    "    loaded_hawkes_data = pickle.load(f)\n",
    "\n",
    "\n",
    "seq_times, seq_types, seq_lengths, _ = process_loaded_sequences(loaded_hawkes_data, 2)\n",
    "\n",
    "total_sample_size = seq_times.size(0)\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * total_sample_size)\n",
    "dev_ratio =0.1\n",
    "dev_size = int(dev_ratio * total_sample_size)\n",
    "## Split Traning and Test Sets\n",
    "train_seq_times = seq_times[:train_size]\n",
    "train_seq_types = seq_types[:train_size]\n",
    "train_seq_lengths = seq_lengths[:train_size]\n",
    "\n",
    "\n",
    "dev_seq_times = seq_times[train_size:train_size + dev_size]  # train_size+dev_size\n",
    "dev_seq_types = seq_types[train_size:train_size + dev_size]\n",
    "dev_seq_lengths = seq_lengths[train_size:train_size + dev_size]\n",
    "\n",
    "test_seq_times = seq_times[-dev_size:]\n",
    "test_seq_types = seq_types[-dev_size:]\n",
    "test_seq_lengths = seq_lengths[-dev_size:]\n",
    "\n",
    "\n",
    "## sequence length\n",
    "train_seq_lengths, reorder_indices_train = train_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "train_seq_times = train_seq_times[reorder_indices_train]\n",
    "train_seq_types = train_seq_types[reorder_indices_train]\n",
    "#\n",
    "dev_seq_lengths, reorder_indices_dev = dev_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "dev_seq_times = dev_seq_times[reorder_indices_dev]\n",
    "dev_seq_types = dev_seq_types[reorder_indices_dev]\n",
    "\n",
    "test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "test_seq_times = test_seq_times[reorder_indices_test]\n",
    "test_seq_types = test_seq_types[reorder_indices_test]\n",
    "\n",
    "max_sequence_length = max(train_seq_lengths[0], dev_seq_lengths[0], test_seq_lengths[0])\n",
    "print('max_sequence_length: {}'.format(max_sequence_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T03:59:48.065939Z",
     "start_time": "2021-10-14T03:59:48.049017Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_attention_scores_for_sahp(data,model):\n",
    "    tmax = loaded_hawkes_data['tmax']\n",
    "\n",
    "    seq_times, seq_types, seq_lengths, _ = process_loaded_sequences(loaded_hawkes_data, 2)\n",
    "\n",
    "    total_sample_size = seq_times.size(0)\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(train_ratio * total_sample_size)\n",
    "    dev_ratio =0.1\n",
    "    dev_size = int(dev_ratio * total_sample_size)\n",
    "    ## Split Traning and Test Sets\n",
    "    train_seq_times = seq_times[:train_size]\n",
    "    train_seq_types = seq_types[:train_size]\n",
    "    train_seq_lengths = seq_lengths[:train_size]\n",
    "\n",
    "\n",
    "    dev_seq_times = seq_times[train_size:train_size + dev_size]  # train_size+dev_size\n",
    "    dev_seq_types = seq_types[train_size:train_size + dev_size]\n",
    "    dev_seq_lengths = seq_lengths[train_size:train_size + dev_size]\n",
    "\n",
    "    test_seq_times = seq_times[-dev_size:]\n",
    "    test_seq_types = seq_types[-dev_size:]\n",
    "    test_seq_lengths = seq_lengths[-dev_size:]\n",
    "\n",
    "\n",
    "    ## sequence length\n",
    "    train_seq_lengths, reorder_indices_train = train_seq_lengths.sort(descending=True)\n",
    "    # # Reorder by descending sequence length\n",
    "    train_seq_times = train_seq_times[reorder_indices_train]\n",
    "    train_seq_types = train_seq_types[reorder_indices_train]\n",
    "    #\n",
    "    dev_seq_lengths, reorder_indices_dev = dev_seq_lengths.sort(descending=True)\n",
    "    # # Reorder by descending sequence length\n",
    "    dev_seq_times = dev_seq_times[reorder_indices_dev]\n",
    "    dev_seq_types = dev_seq_types[reorder_indices_dev]\n",
    "\n",
    "    test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "    # # Reorder by descending sequence length\n",
    "    test_seq_times = test_seq_times[reorder_indices_test]\n",
    "    test_seq_types = test_seq_types[reorder_indices_test]\n",
    "\n",
    "    max_sequence_length = max(train_seq_lengths[0], dev_seq_lengths[0], test_seq_lengths[0])\n",
    "    print('max_sequence_length: {}'.format(max_sequence_length))\n",
    "    \n",
    "    \n",
    "    batch_size = 1\n",
    "    device = 'cpu'\n",
    "\n",
    "    kernels = [[],[],[],[]]\n",
    "    all_times = [[],[],[],[]]\n",
    "    for i_batch in range(400):\n",
    "        batch_onehot, batch_seq_times, batch_dt, batch_seq_types, _, _, _, batch_seq_lengths = \\\n",
    "        get_batch(batch_size, i_batch, model, test_seq_lengths, test_seq_times, test_seq_types,\n",
    "                       rnn=False)\n",
    "\n",
    "        batch_seq_types = batch_seq_types[:, 1:]\n",
    "\n",
    "        masked_seq_types = MaskBatch(batch_seq_types, pad=model.process_dim,\n",
    "                                     device=device)  # exclude the first added even\n",
    "\n",
    "        model.forward(batch_dt, masked_seq_types.src, masked_seq_types.src_mask)\n",
    "\n",
    "\n",
    "\n",
    "        type_embedding = model.type_emb(batch_seq_types) * math.sqrt(model.d_model)  #\n",
    "        position_embedding = model.position_emb(batch_seq_types, batch_dt)\n",
    "        x = type_embedding + position_embedding\n",
    "\n",
    "        (xt_bar, xt) = get_pairwise_times(batch_seq_times[:,1:])\n",
    "        d = torch.abs(xt_bar - xt)\n",
    "        xd_bar, xd = get_pairwise_times(batch_seq_types)\n",
    "        scores = model.attention.scores[:,1,:,:]\n",
    "    # scores =scores[0].unsqueeze(0)\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                mask = (xd_bar==i)*(xd ==j)\n",
    "                times = d[mask]\n",
    "                kernel = scores[mask]\n",
    "                if i ==0 and j == 0:\n",
    "                    index =0\n",
    "                elif i ==0 and j ==1:\n",
    "                    index =1\n",
    "                elif i ==1 and j ==0:\n",
    "                    index = 2\n",
    "                else:\n",
    "                    index = 3\n",
    "                all_times[index].append(times.detach().numpy())\n",
    "                kernels[index].append(kernel.detach().numpy())\n",
    "                \n",
    "    times = np.concatenate(all_times[1])\n",
    "    k_val = np.concatenate(kernels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:05:42.075802Z",
     "start_time": "2021-10-14T12:05:27.148578Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "device = 'cpu'\n",
    "\n",
    "kernels = [[],[],[],[]]\n",
    "all_times = [[],[],[],[]]\n",
    "for i_batch in range(400):\n",
    "    batch_onehot, batch_seq_times, batch_dt, batch_seq_types, _, _, _, batch_seq_lengths = \\\n",
    "    get_batch(batch_size, i_batch, model, test_seq_lengths, test_seq_times, test_seq_types,\n",
    "                   rnn=False)\n",
    "\n",
    "    batch_seq_types = batch_seq_types[:, 1:]\n",
    "\n",
    "    masked_seq_types = MaskBatch(batch_seq_types, pad=model.process_dim,\n",
    "                                 device=device)  # exclude the first added even\n",
    "    \n",
    "    model.forward(batch_dt, masked_seq_types.src, masked_seq_types.src_mask)\n",
    "    \n",
    "    \n",
    "\n",
    "    type_embedding = model.type_emb(batch_seq_types) * math.sqrt(model.d_model)  #\n",
    "    position_embedding = model.position_emb(batch_seq_types, batch_dt)\n",
    "    x = type_embedding + position_embedding\n",
    "\n",
    "    (xt_bar, xt) = get_pairwise_times(batch_seq_times[:,1:])\n",
    "    d = torch.abs(xt_bar - xt)\n",
    "    xd_bar, xd = get_pairwise_times(batch_seq_types)\n",
    "    scores = model.attention.scores[:,1,:,:]\n",
    "# scores =scores[0].unsqueeze(0)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            mask = (xd_bar==i)*(xd ==j)\n",
    "            times = d[mask]\n",
    "            kernel = scores[mask]\n",
    "            if i ==0 and j == 0:\n",
    "                index =0\n",
    "            elif i ==0 and j ==1:\n",
    "                index =1\n",
    "            elif i ==1 and j ==0:\n",
    "                index = 2\n",
    "            else:\n",
    "                index = 3\n",
    "            all_times[index].append(times.detach().numpy())\n",
    "            kernels[index].append(kernel.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:56:41.688890Z",
     "start_time": "2021-10-14T02:56:34.922311Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 400/400 [00:06<00:00, 59.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 2.2363861209728695\n",
      "Type prediction score: 0.5575\n",
      "tensor(0.0201)\n"
     ]
    }
   ],
   "source": [
    "## Get Result Metrics\n",
    "avg_rmse, types_predict_score, results = prediction_evaluation(\n",
    "    device, model, test_seq_lengths, test_seq_times, test_seq_types, 1, tmax)\n",
    "\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T09:39:00.198064Z",
     "start_time": "2021-10-14T09:39:00.060379Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_seq_types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0beb2fc9ccc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbatch_seq_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_seq_types' is not defined"
     ]
    }
   ],
   "source": [
    "batch_seq_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:17:52.173725Z",
     "start_time": "2021-10-14T04:17:52.163753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10150479, dtype=torch.int32)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_seq_lengths**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:04:53.539533Z",
     "start_time": "2021-10-14T12:04:53.479719Z"
    }
   },
   "outputs": [],
   "source": [
    "times = [np.concatenate(cur) for cur in all_times]\n",
    "k_val = [np.concatenate(cur) for cur in kernels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T04:04:16.668157Z",
     "start_time": "2021-10-14T04:04:16.280842Z"
    }
   },
   "outputs": [],
   "source": [
    "# times = np.concatenate(all_times[0])\n",
    "# k_val = np.concatenate(kernels[1])    \n",
    "# triggering_kernels = {'times':times,'scores':k_val}\n",
    "# np.save('sahp_kernels.npy',triggering_kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:26:05.482007Z",
     "start_time": "2021-10-14T02:26:04.392692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = np.concatenate(all_times[1])\n",
    "sns.distplot(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T02:26:45.474115Z",
     "start_time": "2021-10-14T02:26:45.457161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.       , 47.88739  , 93.00654  , ..., 11.193436 , 46.539505 ,\n",
       "        3.1424942], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_val = times[sorted_index]\n",
    "t_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T12:05:48.812942Z",
     "start_time": "2021-10-14T12:05:47.114633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aa0e2cc8c8>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#11\n",
    "\n",
    "\n",
    "times = np.concatenate(all_times[0])\n",
    "k_val = np.concatenate(kernels[0])\n",
    "sorted_index = np.argsort(times)\n",
    "t_val = times[sorted_index]\n",
    "k_val = k_val[sorted_index]\n",
    "\n",
    "\n",
    "moving_average = 100\n",
    "\n",
    "## Moving Average \n",
    "k_val = np.convolve(k_val, np.ones(moving_average), 'valid') / moving_average    \n",
    "t_val = np.convolve(t_val, np.ones(moving_average), 'valid') / moving_average\n",
    "\n",
    "plt.plot(t_val,k_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T03:09:42.312627Z",
     "start_time": "2021-10-14T03:09:42.292674Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('data/mimic/test_manifold_format.pkl', 'rb') as f:\n",
    "    loaded_hawkes_data = pickle.load(f)\n",
    "\n",
    "\n",
    "test_seq_times, test_seq_types, test_seq_lengths, _ = process_loaded_sequences(loaded_hawkes_data, 75)\n",
    "\n",
    "test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "test_seq_times = test_seq_times[reorder_indices_test]\n",
    "test_seq_types = test_seq_types[reorder_indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T03:13:25.943498Z",
     "start_time": "2021-10-14T03:13:25.909400Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SAHP:\n\tsize mismatch for type_emb.weight: copying a param with shape torch.Size([76, 32]) from checkpoint, the shape in current model is torch.Size([76, 16]).\n\tsize mismatch for position_emb.div_term: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for position_emb.Wt.weight: copying a param with shape torch.Size([16, 1]) from checkpoint, the shape in current model is torch.Size([8, 1]).\n\tsize mismatch for attention.linear_layers.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.linear_layers.1.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.linear_layers.2.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.output_linear.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.output_linear.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for feed_forward.w_1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([64, 16]).\n\tsize mismatch for feed_forward.w_1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for feed_forward.w_2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).\n\tsize mismatch for feed_forward.w_2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for input_sublayer.norm.a_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for input_sublayer.norm.b_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for output_sublayer.norm.a_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for output_sublayer.norm.b_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for start_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for start_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for converge_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for converge_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decay_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decay_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for intensity_layer.0.weight: copying a param with shape torch.Size([75, 32]) from checkpoint, the shape in current model is torch.Size([75, 16]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-d280a6f9dcb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sahp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m34\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprocess_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models/sahp-mimic_hidden16-20211012-005042'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1407\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1408\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SAHP:\n\tsize mismatch for type_emb.weight: copying a param with shape torch.Size([76, 32]) from checkpoint, the shape in current model is torch.Size([76, 16]).\n\tsize mismatch for position_emb.div_term: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n\tsize mismatch for position_emb.Wt.weight: copying a param with shape torch.Size([16, 1]) from checkpoint, the shape in current model is torch.Size([8, 1]).\n\tsize mismatch for attention.linear_layers.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.linear_layers.1.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.linear_layers.2.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.linear_layers.2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for attention.output_linear.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for attention.output_linear.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for feed_forward.w_1.weight: copying a param with shape torch.Size([128, 32]) from checkpoint, the shape in current model is torch.Size([64, 16]).\n\tsize mismatch for feed_forward.w_1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for feed_forward.w_2.weight: copying a param with shape torch.Size([32, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).\n\tsize mismatch for feed_forward.w_2.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for input_sublayer.norm.a_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for input_sublayer.norm.b_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for output_sublayer.norm.a_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for output_sublayer.norm.b_2: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for start_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for start_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for converge_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for converge_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for decay_layer.0.weight: copying a param with shape torch.Size([32, 32]) from checkpoint, the shape in current model is torch.Size([16, 16]).\n\tsize mismatch for decay_layer.0.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n\tsize mismatch for intensity_layer.0.weight: copying a param with shape torch.Size([75, 32]) from checkpoint, the shape in current model is torch.Size([75, 16])."
     ]
    }
   ],
   "source": [
    "\n",
    "model = train_sahp.make_model(max_sequence_length=34,process_dim=75)\n",
    "model_dict =torch.load('saved_models/sahp-mimic_hidden16-20211012-005042',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T03:06:37.030952Z",
     "start_time": "2021-10-14T03:06:37.026963Z"
    }
   },
   "outputs": [],
   "source": [
    "### StackOverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:34:08.424646Z",
     "start_time": "2021-10-14T06:34:07.718535Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load Data Set\n",
    "dataset = 'retweet'\n",
    "process_dim =3 \n",
    "\n",
    "train_path = 'data/' + dataset + '/train_manifold_format.pkl'\n",
    "dev_path = 'data/' + dataset + '/dev_manifold_format.pkl'\n",
    "test_path = 'data/' + dataset + '/test_manifold_format.pkl'\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    train_hawkes_data = pickle.load(f)\n",
    "with open(dev_path, 'rb') as f:\n",
    "    dev_hawkes_data = pickle.load(f)\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_hawkes_data = pickle.load(f)\n",
    "\n",
    "train_seq_times, train_seq_types, train_seq_lengths, train_tmax = \\\n",
    "process_loaded_sequences(train_hawkes_data, process_dim)\n",
    "dev_seq_times, dev_seq_types, dev_seq_lengths, dev_tmax = \\\n",
    "process_loaded_sequences(dev_hawkes_data, process_dim)\n",
    "test_seq_times, test_seq_types, test_seq_lengths, test_tmax = \\\n",
    "process_loaded_sequences(test_hawkes_data, process_dim)\n",
    "\n",
    "tmax = max([train_tmax, dev_tmax, test_tmax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:24:59.914781Z",
     "start_time": "2021-10-14T06:24:59.901849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 4.6296e-05, 4.7950e-05,  ..., 6.2721e-01, 7.4688e-01,\n",
       "         8.6557e-01],\n",
       "        [0.0000e+00, 2.6439e-03, 3.3003e-03,  ..., 1.0255e-01, 1.6000e-01,\n",
       "         2.7989e-01],\n",
       "        [0.0000e+00, 2.1495e-05, 2.8109e-05,  ..., 9.1505e-01, 9.1533e-01,\n",
       "         9.2075e-01],\n",
       "        ...,\n",
       "        [0.0000e+00, 4.4643e-05, 5.7871e-05,  ..., 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [0.0000e+00, 2.1495e-05, 3.9683e-05,  ..., 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00],\n",
       "        [0.0000e+00, 3.3069e-05, 5.1257e-05,  ..., 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq_times/tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:34:12.268726Z",
     "start_time": "2021-10-14T06:34:12.206858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample size: 20000\n",
      "Dev sample size: 2000\n",
      "Test sample size: 2000\n",
      "No. of event tokens in training subset: tensor(2176116)\n",
      "No. of event tokens in development subset: tensor(215521)\n",
      "No. of event tokens in test subset: tensor(218465)\n",
      "max_sequence_length: 264\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "train_sample_size = train_seq_times.size(0)\n",
    "print(\"Train sample size: {}\".format(train_sample_size))\n",
    "\n",
    "dev_sample_size = dev_seq_times.size(0)\n",
    "print(\"Dev sample size: {}\".format(dev_sample_size))\n",
    "\n",
    "test_sample_size = test_seq_times.size(0)\n",
    "print(\"Test sample size: {}\".format(test_sample_size))\n",
    "\n",
    "\n",
    "# Define training data\n",
    "train_seq_times = train_seq_times.to(device)\n",
    "train_seq_types = train_seq_types.to(device)\n",
    "train_seq_lengths = train_seq_lengths.to(device)\n",
    "print(\"No. of event tokens in training subset:\", train_seq_lengths.sum())\n",
    "\n",
    "# Define development data\n",
    "dev_seq_times = dev_seq_times.to(device)\n",
    "dev_seq_types = dev_seq_types.to(device)\n",
    "dev_seq_lengths = dev_seq_lengths.to(device)\n",
    "print(\"No. of event tokens in development subset:\", dev_seq_lengths.sum())\n",
    "\n",
    "# Define test data\n",
    "test_seq_times = test_seq_times.to(device)\n",
    "test_seq_types = test_seq_types.to(device)\n",
    "test_seq_lengths = test_seq_lengths.to(device)\n",
    "print(\"No. of event tokens in test subset:\", test_seq_lengths.sum())\n",
    "\n",
    "\n",
    "## sequence length\n",
    "train_seq_lengths, reorder_indices_train = train_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "train_seq_times = train_seq_times[reorder_indices_train]\n",
    "train_seq_types = train_seq_types[reorder_indices_train]\n",
    "#\n",
    "dev_seq_lengths, reorder_indices_dev = dev_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "dev_seq_times = dev_seq_times[reorder_indices_dev]\n",
    "dev_seq_types = dev_seq_types[reorder_indices_dev]\n",
    "\n",
    "test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "test_seq_times = test_seq_times[reorder_indices_test]\n",
    "test_seq_types = test_seq_types[reorder_indices_test]\n",
    "\n",
    "max_sequence_length = max(train_seq_lengths[0], dev_seq_lengths[0], test_seq_lengths[0])\n",
    "print('max_sequence_length: {}'.format(max_sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:34:13.896605Z",
     "start_time": "2021-10-14T06:34:13.870701Z"
    }
   },
   "outputs": [],
   "source": [
    "model = train_sahp.make_model(max_sequence_length=max_sequence_length+1, process_dim=3)\n",
    "model_dict =torch.load('saved_models/retweet/sahp-retweet_hidden16-20211014-020232',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "batch_size = 32\n",
    "test_size = test_seq_times.size(0)\n",
    "device = 'cpu'\n",
    "test_loop_range = list(range(0, test_size, batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:34:50.316656Z",
     "start_time": "2021-10-14T06:34:21.158070Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2000/2000 [00:28<00:00, 69.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 127645.66957010332\n",
      "Type prediction score: 0.531\n"
     ]
    }
   ],
   "source": [
    "avg_rmse, types_predict_score, results = prediction_evaluation(\n",
    "    device, model, test_seq_lengths, test_seq_times, test_seq_types, 1, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:35:22.991945Z",
     "start_time": "2021-10-14T06:34:52.781929Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2000/2000 [00:30<00:00, 66.35it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = (test_seq_times, test_seq_types, test_seq_lengths)\n",
    "incr_estimates, incr_reals, types_real, types_estimates = \\\n",
    "    evaluation.predict_test(model, *test_data, pad=model.process_dim, device=device,\n",
    "                            hmax=tmax, use_jupyter=False, rnn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:42:35.450312Z",
     "start_time": "2021-10-14T06:42:35.430377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16279273000.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(incr_reals-incr_estimates)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:39:39.244794Z",
     "start_time": "2021-10-14T06:39:39.230836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.138854"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((np.abs(incr_estimates[incr_reals!=0] -incr_reals[incr_reals!=0])/incr_reals[incr_reals!=0])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T06:37:58.585968Z",
     "start_time": "2021-10-14T06:37:58.574997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " incr_reals==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T03:51:48.073185Z",
     "start_time": "2021-07-28T03:51:47.915135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size: 4000\n",
      "Train sample size: 3200/4000\n",
      "Dev sample size: 400/4000\n",
      "No. of event tokens in training subset: tensor(498611)\n",
      "No. of event tokens in development subset: tensor(63349)\n",
      "No. of event tokens in test subset: tensor(61657)\n",
      "max_sequence_length: 323\n",
      "the number of trainable parameters: 4186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SAHP(\n",
       "  (gelu): GELU()\n",
       "  (type_emb): TypeEmbedding(3, 16, padding_idx=2)\n",
       "  (position_emb): BiasedPositionalEmbedding(\n",
       "    (Wt): Linear(in_features=1, out_features=8, bias=False)\n",
       "  )\n",
       "  (attention): MultiHeadedAttention(\n",
       "    (linear_layers): ModuleList(\n",
       "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (output_linear): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (attention): Attention()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (feed_forward): PositionwiseFeedForward(\n",
       "    (w_1): Linear(in_features=16, out_features=64, bias=True)\n",
       "    (w_2): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation): GELU()\n",
       "  )\n",
       "  (input_sublayer): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (output_sublayer): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (start_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): GELU()\n",
       "  )\n",
       "  (converge_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): GELU()\n",
       "  )\n",
       "  (decay_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (1): Softplus(beta=10.0, threshold=20)\n",
       "  )\n",
       "  (intensity_layer): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=2, bias=True)\n",
       "    (1): Softplus(beta=1.0, threshold=20)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_dim = 2\n",
    "device = 'cpu'\n",
    "train_ratio = 0.8\n",
    "lr = 5e-5\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "with open('data/simulated/hawkes_synthetic_random_2d_20191130-180837.pkl', 'rb') as f:\n",
    "    loaded_hawkes_data = pickle.load(f)\n",
    "    \n",
    "process_dim = loaded_hawkes_data['process_dim'] if 'process_dim' in loaded_hawkes_data.keys() else process_dim\n",
    "\n",
    "seq_times, seq_types, seq_lengths, _ = process_loaded_sequences(loaded_hawkes_data, process_dim)\n",
    "\n",
    "seq_times = seq_times.to(device)\n",
    "seq_types = seq_types.to(device)\n",
    "seq_lengths = seq_lengths.to(device)\n",
    "\n",
    "total_sample_size = seq_times.size(0)\n",
    "print(\"Total sample size: {}\".format(total_sample_size))\n",
    "\n",
    "train_size = int(train_ratio * total_sample_size)\n",
    "dev_ratio = 0.1\n",
    "dev_size = int(dev_ratio * total_sample_size)\n",
    "print(\"Train sample size: {:}/{:}\".format(train_size, total_sample_size))\n",
    "print(\"Dev sample size: {:}/{:}\".format(dev_size, total_sample_size))\n",
    "\n",
    "# Define training data\n",
    "train_seq_times = seq_times[:train_size]\n",
    "train_seq_types = seq_types[:train_size]\n",
    "train_seq_lengths = seq_lengths[:train_size]\n",
    "print(\"No. of event tokens in training subset:\", train_seq_lengths.sum())\n",
    "\n",
    "# Define development data\n",
    "dev_seq_times = seq_times[train_size:train_size + dev_size]  # train_size+dev_size\n",
    "dev_seq_types = seq_types[train_size:train_size + dev_size]\n",
    "dev_seq_lengths = seq_lengths[train_size:train_size + dev_size]\n",
    "print(\"No. of event tokens in development subset:\", dev_seq_lengths.sum())\n",
    "\n",
    "test_seq_times = seq_times[-dev_size:]\n",
    "test_seq_types = seq_types[-dev_size:]\n",
    "test_seq_lengths = seq_lengths[-dev_size:]\n",
    "\n",
    "print(\"No. of event tokens in test subset:\", test_seq_lengths.sum())\n",
    "\n",
    "## sequence length\n",
    "train_seq_lengths, reorder_indices_train = train_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "train_seq_times = train_seq_times[reorder_indices_train]\n",
    "train_seq_types = train_seq_types[reorder_indices_train]\n",
    "#\n",
    "dev_seq_lengths, reorder_indices_dev = dev_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "dev_seq_times = dev_seq_times[reorder_indices_dev]\n",
    "dev_seq_types = dev_seq_types[reorder_indices_dev]\n",
    "\n",
    "test_seq_lengths, reorder_indices_test = test_seq_lengths.sort(descending=True)\n",
    "# # Reorder by descending sequence length\n",
    "test_seq_times = test_seq_times[reorder_indices_test]\n",
    "test_seq_types = test_seq_types[reorder_indices_test]\n",
    "\n",
    "max_sequence_length = max(train_seq_lengths[0], dev_seq_lengths[0], test_seq_lengths[0])\n",
    "print('max_sequence_length: {}'.format(max_sequence_length))\n",
    "\n",
    "\n",
    "d_model = 16\n",
    "atten_heads = 1\n",
    "dropout = 0.1\n",
    "\n",
    "model = make_model(nLayers=1, d_model=d_model, atten_heads=atten_heads,\n",
    "                   dropout=dropout, process_dim=process_dim, device=device, pe='add',\n",
    "                   max_sequence_length=max_sequence_length + 1).to(device)\n",
    "\n",
    "print(\"the number of trainable parameters: \" + str(count_parameters(model)))\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=3e-4)\n",
    "model_opt = NoamOpt(d_model, 1, 100, initial_lr=lr, optimizer=optimizer)\n",
    "\n",
    "\n",
    "## Size of the traing dataset\n",
    "train_size = train_seq_times.size(0)\n",
    "dev_size = dev_seq_times.size(0)\n",
    "test_size = test_seq_times.size(0)\n",
    "tr_loop_range = list(range(0, train_size, batch_size))\n",
    "de_loop_range = list(range(0, dev_size, batch_size))\n",
    "test_loop_range = list(range(0, test_size, batch_size))\n",
    "\n",
    "last_dev_loss = 0.0\n",
    "early_step = 0\n",
    "\n",
    "random_seeds = list(range(0, 1000))\n",
    "random.shuffle(random_seeds)\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:03:13.623046Z",
     "start_time": "2021-07-28T04:03:13.523347Z"
    }
   },
   "outputs": [],
   "source": [
    "i_batch = 0\n",
    "model_opt.optimizer.zero_grad()\n",
    "\n",
    "batch_onehot, batch_seq_times, batch_dt, batch_seq_types, _, _, _, batch_seq_lengths = \\\n",
    "    get_batch(batch_size, i_batch, model, train_seq_lengths, train_seq_times, train_seq_types,\n",
    "                   rnn=False)\n",
    "\n",
    "batch_seq_types = batch_seq_types[:, 1:]\n",
    "\n",
    "masked_seq_types = MaskBatch(batch_seq_types, pad=model.process_dim,\n",
    "                             device=device)  # exclude the first added even\n",
    "model.forward(batch_dt, masked_seq_types.src, masked_seq_types.src_mask)\n",
    "# nll = model.compute_loss(batch_seq_times, batch_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:22:55.043265Z",
     "start_time": "2021-07-28T04:22:55.020327Z"
    }
   },
   "outputs": [],
   "source": [
    "### Loss Function\n",
    "def compute_loss(model,seq_times,seq_onehot_types,n_mc_samples = 20):\n",
    "    dt_seq = seq_times[:, 1:] - seq_times[:, :-1]\n",
    "    cell_t = model.state_decay(model.converge_point, model.start_point, model.omega, dt_seq[:, :, None])\n",
    "\n",
    "    n_batch = seq_times.size(0)\n",
    "    n_times = seq_times.size(1) - 1\n",
    "    device = dt_seq.device\n",
    "    # Get the intensity process\n",
    "    intens_at_evs = model.intensity_layer(cell_t)\n",
    "    \n",
    "    \n",
    "    log_intensities = intens_at_evs.log()  # log intensities\n",
    "    log_intensities =  log_intensities*seq_onehot_types[:, 1:, :].sum(dim=-1).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    seq_mask = seq_onehot_types[:, 1:]\n",
    "    log_sum = (log_intensities * seq_mask).sum(dim=(2, 1)) \n",
    "    \n",
    "    \n",
    "    taus = torch.rand(n_batch, n_times, 1, n_mc_samples).to(device) \n",
    "    taus = dt_seq[:, :, None, None] * taus \n",
    "    \n",
    "    \n",
    "    cell_tau = model.state_decay(\n",
    "    model.converge_point[:, :, :, None],\n",
    "    model.start_point[:, :, :, None],\n",
    "    model.omega[:, :, :, None],\n",
    "    taus)\n",
    "    \n",
    "    cell_tau = cell_tau.transpose(2, 3)\n",
    "    intens_at_samples = model.intensity_layer(cell_tau).transpose(2, 3)\n",
    "    intens_at_samples = intens_at_samples*seq_onehot_types[:, 1:, :].sum(dim=-1).unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    total_intens_samples = intens_at_samples.sum(dim=2)  # shape batch * N * MC\n",
    "    partial_integrals = dt_seq * total_intens_samples.mean(dim=2)\n",
    "\n",
    "    integral_ = partial_integrals.sum(dim=1)\n",
    "\n",
    "    res = torch.sum(- log_sum + integral_)\n",
    "    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Other 2-D Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:26:54.485162Z",
     "start_time": "2021-07-28T04:26:54.429348Z"
    }
   },
   "outputs": [],
   "source": [
    "process_dim = 2\n",
    "device = 'cpu'\n",
    "train_ratio = 0.8\n",
    "lr = 5e-5\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "with open('data/simulated/hawkes_2d.pkl', 'rb') as f:\n",
    "    loaded_hawkes_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:27:03.049518Z",
     "start_time": "2021-07-28T04:27:03.044531Z"
    }
   },
   "outputs": [],
   "source": [
    "process_dim = loaded_hawkes_data['process_dim'] if 'process_dim' in loaded_hawkes_data.keys() else process_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-28T04:27:06.097620Z",
     "start_time": "2021-07-28T04:27:06.090606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
